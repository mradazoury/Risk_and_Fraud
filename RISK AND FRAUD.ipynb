{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model With sklearn - Lending Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## whats this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "import gc\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.impute  import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_df = pd.read_csv('./loan.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with a copy of dataset to avoid having to reload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>url</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>...</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>annual_inc_joint</th>\n",
       "      <th>dti_joint</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_il_6m</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I need to upgra...</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>860xx</td>\n",
       "      <td>AZ</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>171.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use t...</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>309xx</td>\n",
       "      <td>GA</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Apr-2013</td>\n",
       "      <td>119.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>small_business</td>\n",
       "      <td>real estate business</td>\n",
       "      <td>606xx</td>\n",
       "      <td>IL</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov-2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jun-2014</td>\n",
       "      <td>649.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n",
       "      <td>other</td>\n",
       "      <td>personel</td>\n",
       "      <td>917xx</td>\n",
       "      <td>CA</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-1996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>357.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>University Medical Group</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Current</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; I plan on combi...</td>\n",
       "      <td>other</td>\n",
       "      <td>Personal</td>\n",
       "      <td>972xx</td>\n",
       "      <td>OR</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Feb-2016</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430    1314167     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175    1313524     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863    1277178    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358    1311748     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
       "0     10.65       162.87     B        B2                       NaN  10+ years   \n",
       "1     15.27        59.83     C        C4                     Ryder   < 1 year   \n",
       "2     15.96        84.33     C        C5                       NaN  10+ years   \n",
       "3     13.49       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
       "4     12.69        67.79     B        B5  University Medical Group     1 year   \n",
       "\n",
       "  home_ownership  annual_inc verification_status   issue_d  loan_status  \\\n",
       "0           RENT     24000.0            Verified  Dec-2011   Fully Paid   \n",
       "1           RENT     30000.0     Source Verified  Dec-2011  Charged Off   \n",
       "2           RENT     12252.0        Not Verified  Dec-2011   Fully Paid   \n",
       "3           RENT     49200.0     Source Verified  Dec-2011   Fully Paid   \n",
       "4           RENT     80000.0     Source Verified  Dec-2011      Current   \n",
       "\n",
       "  pymnt_plan                                                url  \\\n",
       "0          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "1          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "2          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "3          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "4          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "\n",
       "                                                desc         purpose  \\\n",
       "0    Borrower added on 12/22/11 > I need to upgra...     credit_card   \n",
       "1    Borrower added on 12/22/11 > I plan to use t...             car   \n",
       "2                                                NaN  small_business   \n",
       "3    Borrower added on 12/21/11 > to pay for prop...           other   \n",
       "4    Borrower added on 12/21/11 > I plan on combi...           other   \n",
       "\n",
       "                  title zip_code addr_state    dti  delinq_2yrs  \\\n",
       "0              Computer    860xx         AZ  27.65          0.0   \n",
       "1                  bike    309xx         GA   1.00          0.0   \n",
       "2  real estate business    606xx         IL   8.72          0.0   \n",
       "3              personel    917xx         CA  20.00          0.0   \n",
       "4              Personal    972xx         OR  17.94          0.0   \n",
       "\n",
       "  earliest_cr_line  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0         Jan-1985             1.0                     NaN   \n",
       "1         Apr-1999             5.0                     NaN   \n",
       "2         Nov-2001             2.0                     NaN   \n",
       "3         Feb-1996             1.0                    35.0   \n",
       "4         Jan-1996             0.0                    38.0   \n",
       "\n",
       "   mths_since_last_record  ...  collection_recovery_fee  last_pymnt_d  \\\n",
       "0                     NaN  ...                     0.00      Jan-2015   \n",
       "1                     NaN  ...                     1.11      Apr-2013   \n",
       "2                     NaN  ...                     0.00      Jun-2014   \n",
       "3                     NaN  ...                     0.00      Jan-2015   \n",
       "4                     NaN  ...                     0.00      Jan-2016   \n",
       "\n",
       "   last_pymnt_amnt  next_pymnt_d  last_credit_pull_d  \\\n",
       "0           171.62           NaN            Jan-2016   \n",
       "1           119.66           NaN            Sep-2013   \n",
       "2           649.91           NaN            Jan-2016   \n",
       "3           357.48           NaN            Jan-2015   \n",
       "4            67.79      Feb-2016            Jan-2016   \n",
       "\n",
       "  collections_12_mths_ex_med  mths_since_last_major_derog  policy_code  \\\n",
       "0                        0.0                          NaN          1.0   \n",
       "1                        0.0                          NaN          1.0   \n",
       "2                        0.0                          NaN          1.0   \n",
       "3                        0.0                          NaN          1.0   \n",
       "4                        0.0                          NaN          1.0   \n",
       "\n",
       "   application_type  annual_inc_joint  dti_joint  verification_status_joint  \\\n",
       "0        INDIVIDUAL               NaN        NaN                        NaN   \n",
       "1        INDIVIDUAL               NaN        NaN                        NaN   \n",
       "2        INDIVIDUAL               NaN        NaN                        NaN   \n",
       "3        INDIVIDUAL               NaN        NaN                        NaN   \n",
       "4        INDIVIDUAL               NaN        NaN                        NaN   \n",
       "\n",
       "   acc_now_delinq  tot_coll_amt  tot_cur_bal open_acc_6m  open_il_6m  \\\n",
       "0             0.0           NaN          NaN         NaN         NaN   \n",
       "1             0.0           NaN          NaN         NaN         NaN   \n",
       "2             0.0           NaN          NaN         NaN         NaN   \n",
       "3             0.0           NaN          NaN         NaN         NaN   \n",
       "4             0.0           NaN          NaN         NaN         NaN   \n",
       "\n",
       "  open_il_12m open_il_24m  mths_since_rcnt_il  total_bal_il  il_util  \\\n",
       "0         NaN         NaN                 NaN           NaN      NaN   \n",
       "1         NaN         NaN                 NaN           NaN      NaN   \n",
       "2         NaN         NaN                 NaN           NaN      NaN   \n",
       "3         NaN         NaN                 NaN           NaN      NaN   \n",
       "4         NaN         NaN                 NaN           NaN      NaN   \n",
       "\n",
       "  open_rv_12m  open_rv_24m  max_bal_bc all_util  total_rev_hi_lim  inq_fi  \\\n",
       "0         NaN          NaN         NaN      NaN               NaN     NaN   \n",
       "1         NaN          NaN         NaN      NaN               NaN     NaN   \n",
       "2         NaN          NaN         NaN      NaN               NaN     NaN   \n",
       "3         NaN          NaN         NaN      NaN               NaN     NaN   \n",
       "4         NaN          NaN         NaN      NaN               NaN     NaN   \n",
       "\n",
       "   total_cu_tl  inq_last_12m  \n",
       "0          NaN           NaN  \n",
       "1          NaN           NaN  \n",
       "2          NaN           NaN  \n",
       "3          NaN           NaN  \n",
       "4          NaN           NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = start_df.copy(deep=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on problem defined for dataset, we are building a model that will predict whether a user will defaul in future.\n",
    "\n",
    "Therefore, we need to convert the historical loan status categories into a boolean that describes wheter or not the customer defaulted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fully Paid', 'Charged Off', 'Current', 'Default',\n",
       "       'Late (31-120 days)', 'In Grace Period', 'Late (16-30 days)',\n",
       "       'Does not meet the credit policy. Status:Fully Paid',\n",
       "       'Does not meet the credit policy. Status:Charged Off', 'Issued'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines which 'loan status' is considered as 'Defaulted':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = [1 if i in ['Charged Off', 'Does not meet the credit policy. Status:Charged Off', 'Default','Late (31-120 days)','Late (16-30 days)'] else 0 for i in df['loan_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate how much of dataset 'Defaults' based on this description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61176 0.06894010338310913\n"
     ]
    }
   ],
   "source": [
    "print(sum(target_list), sum(target_list)/len(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TARGET'] = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dec-2011', 'Nov-2011', 'Oct-2011', 'Sep-2011', 'Aug-2011',\n",
       "       'Jul-2011', 'Jun-2011', 'May-2011', 'Apr-2011', 'Mar-2011',\n",
       "       'Feb-2011', 'Jan-2011', 'Dec-2010', 'Nov-2010', 'Oct-2010',\n",
       "       'Sep-2010', 'Aug-2010', 'Jul-2010', 'Jun-2010', 'May-2010',\n",
       "       'Apr-2010', 'Mar-2010', 'Feb-2010', 'Jan-2010', 'Dec-2009',\n",
       "       'Nov-2009', 'Oct-2009', 'Sep-2009', 'Aug-2009', 'Jul-2009',\n",
       "       'Jun-2009', 'May-2009', 'Apr-2009', 'Mar-2009', 'Feb-2009',\n",
       "       'Jan-2009', 'Dec-2008', 'Nov-2008', 'Oct-2008', 'Sep-2008',\n",
       "       'Aug-2008', 'Jul-2008', 'Jun-2008', 'May-2008', 'Apr-2008',\n",
       "       'Mar-2008', 'Feb-2008', 'Jan-2008', 'Dec-2007', 'Nov-2007',\n",
       "       'Oct-2007', 'Sep-2007', 'Aug-2007', 'Jul-2007', 'Jun-2007',\n",
       "       'Dec-2013', 'Nov-2013', 'Oct-2013', 'Sep-2013', 'Aug-2013',\n",
       "       'Jul-2013', 'Jun-2013', 'May-2013', 'Apr-2013', 'Mar-2013',\n",
       "       'Feb-2013', 'Jan-2013', 'Dec-2012', 'Nov-2012', 'Oct-2012',\n",
       "       'Sep-2012', 'Aug-2012', 'Jul-2012', 'Jun-2012', 'May-2012',\n",
       "       'Apr-2012', 'Mar-2012', 'Feb-2012', 'Jan-2012', 'Dec-2014',\n",
       "       'Nov-2014', 'Oct-2014', 'Sep-2014', 'Aug-2014', 'Jul-2014',\n",
       "       'Jun-2014', 'May-2014', 'Apr-2014', 'Mar-2014', 'Feb-2014',\n",
       "       'Jan-2014', 'Dec-2015', 'Nov-2015', 'Oct-2015', 'Sep-2015',\n",
       "       'Aug-2015', 'Jul-2015', 'Jun-2015', 'May-2015', 'Apr-2015',\n",
       "       'Mar-2015', 'Feb-2015', 'Jan-2015'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_d'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Last 5 Years of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "df['year'] = df['issue_d'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.year >= 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().values.any())\n",
    "sns.heatmap(df.isnull()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(df, perct_to_remove = 100):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"Dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        columns_to_remove = mis_val_table_ren_columns[mis_val_table_ren_columns['% of Total Values'] > perct_to_remove].index\n",
    "        columns_to_keep = df.iloc[:,~df.columns.isin(columns_to_remove)].columns\n",
    "        return mis_val_table_ren_columns , columns_to_keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_missing_values, col_to_keep = null_values(df , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[col_to_keep]\n",
    "nullCount = df.isnull().sum()\n",
    "nullCount[nullCount>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of column\n",
    "df.dtypes.value_counts().sort_values().plot(kind='barh')\n",
    "plt.title('Number of columns distributed by Data Types',fontsize=20)\n",
    "plt.xlabel('Number of columns',fontsize=15)\n",
    "plt.ylabel('Data type',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Columns that have more than 10 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to easily get columns with specific data type\n",
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save all columns with 'object' datatype (non-numerical)\n",
    "obj_variables = get_specific_columns(df, ['object'], ['TARGET'], ignore_target = True)\n",
    "obj = df[list(obj_variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_much_unique = df.loc[:,~df.columns.isin(obj.loc[:,obj.nunique() > 10].columns)].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[not_to_much_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### why are we doing this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['collections_12_mths_ex_med' , 'tot_coll_amt' ,'id', 'loan_status' ] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullCount = df.isnull().sum()\n",
    "nullCount[nullCount>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### since 5 columns have the same nulls we decided to drop these 29 rows \n",
    "df = df.loc[~df[ 'delinq_2yrs' ].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we use SimpleImputer form sklearn to impute NA, the strategy decided is median to not change the distribution since tehy are skewed\n",
    "imp = SimpleImputer( strategy='median', verbose=1)\n",
    "numericals = list(get_specific_columns(df, ['int64' , 'float64'], ['TARGET'], ignore_target = True))\n",
    "\n",
    "num = df[numericals]\n",
    "\n",
    "df[numericals] =imp.fit_transform(num) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 \n",
    "intrst_per_grade = df[['int_rate','grade']].groupby('grade').agg(['mean','std'])\n",
    "dum = df[['grade','int_rate']].join(intrst_per_grade , on ='grade')\n",
    "dum['intrst_per_grade'] = (dum['int_rate'] - dum[('int_rate', 'mean')]) / dum[('int_rate', 'std')]\n",
    "df['intrst_per_grade']= dum['intrst_per_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 %  last_paymnt_amnt / tot_cur_bal\n",
    "df['perc_last_pay_from_bal'] = df['installment'] / (df['tot_cur_bal'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 [last_pay - ( tot_cur_bal + annual_income/12)] if positive  1(dsnt have wnough money to pay) if negative has 0 \n",
    "df['not_engh_to_pay'] = df['installment'] - df['tot_cur_bal'] - df['annual_inc']/12\n",
    "df['not_engh_to_pay'] = np.where(df['not_engh_to_pay'] > 0, 1, 0).astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numericals = list(get_specific_columns(df, ['int64' , 'float64'], ['TARGET' , 'member_id'], ignore_target = True))\n",
    "num = df[numericals]\n",
    "\n",
    "df[numericals] =scaler.fit_transform(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binnng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skt = KBinsDiscretizer(n_bins = 5 , strategy = 'quantile' , encode = 'ordinal')\n",
    "to_bin = np.array(df['total_pymnt']).reshape(-1, 1)\n",
    "df[['total_pymnt']] = skt.fit_transform(to_bin)\n",
    "df[['total_pymnt']] = df[['total_pymnt']].astype('object' , inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## whats this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### interest rate compared to ppl in ur grade \n",
    "#### %  last_paymnt_amnt / tot_cur_bal\n",
    "####   [last_pay - ( tot_cur_bal + annual_income/12)] if positive  1(dsnt have wnough money to pay) if negative has 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_hot_sklearn(df , categoricals): \n",
    "    df.copy()\n",
    "    for i in categoricals:\n",
    "        print(i)\n",
    "        hot = OneHotEncoder()\n",
    "        X = hot.fit_transform(df[i].values.reshape(-1,1)).toarray()\n",
    "        dfOneHot = pd.DataFrame(X, columns = [str(i)+str('_')+str(j[3:]) for j in hot.get_feature_names()])\n",
    "        dfOneHot['member_id'] = df['member_id']\n",
    "        df = df.merge(dfOneHot,on = 'member_id')\n",
    "        df.drop(i, axis =1 , inplace = True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_variables = list(get_specific_columns(df, ['object'], ['TARGET'], ignore_target = True))\n",
    "df = One_hot_sklearn(df , obj_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,df.columns!='TARGET']\n",
    "y = df['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change this to split based on dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, shuffle = False, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predLog = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRF = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, predRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform grid search with multiple parameter options for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [50, 100, 200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [100, 150]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#         estimator=RandomForestClassifier(),\n",
    "#         param_grid=random_grid,\n",
    "# #         scoring=\"accuracy\",\n",
    "#         scoring = make_scorer(f1_score)\n",
    "#         cv=kfold,\n",
    "#         refit=True,\n",
    "#         n_jobs=-1,\n",
    "#         verbose = 2,\n",
    "# )\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        param_distributions=random_grid,\n",
    "#         scoring=\"accuracy\",\n",
    "        scoring = make_scorer(f1_score),\n",
    "        cv=kfold,\n",
    "        refit=True,\n",
    "        random_state=999,\n",
    "        n_iter = 1,\n",
    "        n_jobs=-1,\n",
    "        verbose = 2,\n",
    ")\n",
    "\n",
    "grid_result = grid_search.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\tAverage result for best Random Forest: {} +/- {:.5f}\".format(\n",
    "        grid_result.best_score_,\n",
    "        grid_result.cv_results_[\"std_test_score\"][\n",
    "            np.argmax(grid_result.cv_results_[\"mean_test_score\"])\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve (Random Forest Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, predRF)\n",
    "print(logit_roc_auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:,1])\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.05])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
